# Exercise 1.45

We saw in 1.3.3 that attempting to compute square roots by naively finding a
fixed point of $y \mapsto x/y$ does not converge, and that this can be fixed by
average damping. The same method works for finding cube roots as fixed points of
the average-damped $y\mapsto x/y^2$. Unfortunately, the process does not work
for fourth roots—a single average damp is not enough to make a fixed-point
search for $y \mapsto x/y^3$ converge. On the other hand, if we average damp
twice (i.e., use the average damp of the average damp of $y \mapsto x/y^3$) the
fixed-point search does converge.

Do some experiments to determine how many average damps are required to compute
$n^{th}$ roots as a fixed-point search based upon repeated average damping of
$y \mapsto x/y^{n−1}$. Use this to implement a simple procedure for computing
$n^{th}$ roots using `fixed-point`, `average-damp`, and the `repeated` procedure
of [Exercise 1.43](./1.43.md). Assume that any arithmetic operations you need
are available as primitives.

## Answer

I can do the experiments and get to the final result. But I want deep
understanding. So I'll attemp to answer these questions:

- For $\sqrt[3]{x}$, why $y \mapsto \frac{x}{y^2}$ doesn't work with 0
  `average-damp` pass?
- For $\sqrt[4]{x}$, why $y \mapsto \frac{x}{y^3}$ doesn't work with 0 or 1
  `average-damp` pass?
- How to find and prove the formula for amount of times? From the exercise and
  the book, we know that:

  | $n$ | amount of `average-damp` |
  | --- | ------------------------ |
  | 1   | 0                        |
  | 2   | 1                        |
  | 3   | 1                        |
  | 4   | 2                        |

  I've added the special case $n = 1$. It's quite easy to see that
  $\lfloor log_2(n)\rfloor$ times of `average-damp` is required. But, why?

- Beside applying `average-damp` multiple times, are there any way to ensure the
  series coverge? See also [Series acceleration][series-acceleration].

[series-acceleration]: https://en.wikipedia.org/wiki/Series_acceleration

From now on, let's use $T_n$ to denote the transformation
$x \mapsto \frac{a}{x^n}$. Our goals are to understand the _shape_ of the series
created by the $T_n$, how average damping can help adjusting its shape and make
the series converge.

Please note that the math definitions, proofs and calculations below are not
rigorous enough. To make it easier and shorter to write, I only consider
positive $a$ and $x$. I believe the findings are correct for any value of $a$
and $x$ such that $x \ne 0$.

### Why direct transformed series doesn't converge?

We will use $T_n^k(x)$ to denote the k-th value after applying $k$ times $T_n$
to $x$. We know that $T_1$ won't convert if $x \ne \sqrt{a}$, as
$T_1^{2k}(x) = x \space \forall k \ge 1$ due to:

$$
\begin{split}
T_1^2(x) & = T_1(T_1(x)) \\
         & = T_1\left(\frac{a}{x}\right) \\
         & = \frac{a}{\frac{a}{x}} \\
         & = x
\end{split}
$$

To see why direct transformed series doesn't converge for $n \gt 1$, we will
prove the following lemma

$$
T_n^2(x) = T_n(T_n(x)) \begin{cases}
\lt x \qquad \forall x < \sqrt[n+1]{a} \\
\gt x \qquad \forall x > \sqrt[n+1]{a} \\
\end{cases}
\tag{1}
$$

Let's see what $T_n^2(x)$ look like.

$$
\begin{split}
T_n^2(x) & = T_n(T_n(x)) \\
         & = T_n\left(\frac{a}{x^n}\right) \\
         & = \frac{a}{(\frac{a}{x^n})^n} \\
         & = \frac{a (x^n)^n}{a^n} \\
         & = \frac{a x^{n^2}}{a^n} \\
         & = \frac{x^{n^2}}{a^{n-1}} \\
         & = x \frac{x^{n^2 - 1}}{a^{n-1}} \\
         & = x \frac{x^{(n - 1)(n+1)}}{a^{n-1}} \\
         & = x \frac{(x^{n+1})^{n-1}}{a^{n-1}} \\
\end{split}
\tag{2}
$$

Now, if $x \gt \sqrt[n+1]{a}$, then $x^{n+1} \gt a$, thus:

$$
\begin{split}
T_n^2(x) & = x \frac{(x^{n+1})^{n-1}}{a^{n-1}} \\
         & \gt x \frac{a^{n-1}}{a^{n-1}} \\
         & \gt x
\end{split}
$$

Similarly, we have $T_n^2(x) \lt x$ when $x \lt \sqrt[n+1]{a}$.

## How average damping help?

From above finding, we can see that the series generated by $T_n$ splits into 2
sequences, $T_n^{2k}(x_0)$ and $T_n^{2k+1}(x_0)$, that went into 2 opposite
directions depends on how the first guess $x_0$ compare to our _target_,
$\sqrt[n+1]{a}$.

To make the whole series converge, intuitively, we want to **pull those values
closer to the target** by apply another transform on top of $T_n$, turn it into
$S_n$, such that the absolute distance between $S_n^k(x)$ become smaller as $k$
go up.

In other word, we need to derive $S_n$ from $T_n$, such that when $k$ is **big
enough**, we will have:

$$
|S_n^k(x) - \sqrt[n+1]{a} | \gt |S_n^{k+1}(x) - \sqrt[n+1]{a}|
\tag{3}
$$

It's now obvious that average damping _might_ help making the series generated
by $T_n$ converges by computing the next value using **2 previous values**: $x$
and $T_n(x)$.

In particular

$$
\begin{split}
S_1(x) & = \frac{1}{x}(x + T_1(x))                \\
       & = \frac{1}{2} x + \frac{1}{2}\frac{a}{x} \\
       & = p_1x + q_1\frac{a}{x}
\end{split}
$$

Here, $p_1 = q_1 = \frac{1}{2}$, the sufficient fractions to make $S_1$
converge. Our **generalized problem** is computed $p_n, q_n$ in terms of $n$
with $n\gt 1$, such that the following transformation converge:

$$
S_n: x \mapsto p_n x + q_n \frac{a}{x^n}
$$

Also, we need $p_n + q_n = 1$, so that $S_n(\sqrt[n+1]{a}) = \sqrt[n+1]{a}$.

The exercise hints that applying multiple average damping multiple times might
help, hence, this transformation _might_ work:

$$
\begin{split}
S_n: x \mapsto &
\frac{1}{2}\left(x +
\frac{1}{2}\left(x + \ldots \left(
\frac{1}{2}\left(x +
\frac{a}{x^n}
\right)
\right)
\right)
\right)
\\
 &= x \left(\frac{1}{2} + \frac{1}{4} + \ldots + \frac{1}{2^r} \right)
    + \frac{a}{x^n} \left(\frac{1}{2} + \frac{1}{4} + \ldots + \frac{1}{2^r} \right) \\
 &= (1 - \frac{1}{2^r})x + \frac{1}{2^r} \frac{a}{x^n}
\end{split}
$$

Thus, there's a $r \in \mathbb{N}$ such that $p_n=1-\frac{1}{2^r}$ and
$q_n = \frac{1}{2^r}$ make $S_n$ converges. The **specialized problem** is to
find $r$.

In the next section, we will analyze the current $S_1$ with
$p_1 = q_1 = \frac{1}{2}$ to understand some properties that guarantee $S_1$
converges.

## The case of square root

Recall that $u+v \ge 2\sqrt{uv}$ if $u\ge 0$ and $u \ge 0$ (simplest non-trivial
case of [AM-GM inequality][am-gm]), also note that $x \gt 0$ (it doesn't make
sense to give a negative _first guess_ for $\sqrt{a}$ anyway), we have the
following property:

[am-gm]: https://en.wikipedia.org/wiki/AM%E2%80%93GM_inequality

$$
\frac{x + \frac{a}{x}}{2} \ge \sqrt{x \frac{a}{x}} = \sqrt{a}
$$

That means, no matter which initial $x$ we choose, $S_1^k(x) \ge \sqrt{a}$ for
all $k \ge 1$.

Now, if $x \gt \sqrt{a}$, we have

$$
\begin{split}
     && |S_1^0(x) - \sqrt{a} | & \gt |S_1^1(x) - \sqrt{a}| \\
\iff && x - \sqrt{a} & \gt S_1^1(x) - \sqrt{a}             \\
\iff && x & \gt \frac{x + a/x}{2}                          \\
\iff && 2x & \gt x + a/x                                   \\
\iff && x & \gt a/x                                        \\
\iff && x^2 & \gt a                                        \\
\end{split}
$$

which is true.

Combine the 2 properties of $S_1$, we can see that no matter what $x$ we choose,
when $k \ge 1$, the expectation $(3)$ is true.

## Idea for $n^{th}$ root

From $p_n + q_n = 1$, we have

$$
\begin{split}
x - S_n(x)
& = x - \left(p_n x + q \frac{a}{x^n}\right) \\
& = (1 - p_n)x - q_n \frac{a}{x^n}           \\
& = q_n x - q_n \frac{a}{x^n}                \\
& = q_n \left(x - \frac{a}{x^n}\right)       \\
& = \frac{q_n}{x^n} (x^{n+1} - a)            \\
\end{split}
$$

Thus, $x \ge \sqrt[n+1]{a} \iff x \ge S_n(x)$ and vice versa.

If we could pick $p_n$ and $q_n$ such that there is a $k'$ which satisfies
$\forall k\ge k', S_n^k(x) \ge \sqrt[n+1]{a}$, we will have $(3)$ satisfied, due
to

$$
\begin{split}
      && |S_n^k(x) - \sqrt[n+1]{a} | &\gt |S_n^{k+1}(x) - \sqrt[n+1]{a}| \\
\iff  && S_n^k(x) - \sqrt[n+1]{a}  &\gt S_n^{k+1}(x) - \sqrt[n+1]{a}     \\
\iff  && S_n^k(x) &\gt S_n^{k+1}(x)                                      \\
\iff  && S_n^k(x) &\gt S_n(S_n^k(x))
\end{split}
$$

By applying AM-GM inequality again to $S_n$, we get:

$$
\begin{split}
p_n x + q_n \frac{a}{x^n} &= n \frac{p_n x}{n} + q_n \frac{a}{x^n} \\
&\ge (n+1)\sqrt[n+1]{\left(\frac{p_n x}{n}\right)^n  q_n \frac{a}{x^n}} \\
&= \sqrt[n+1]{a} (n+1) \sqrt[n+1]{\frac{p_n^n q_n}{n^n}}
\end{split}
\tag{4}
$$

We want our right side of $(4)$ is $\ge \sqrt[n+1]{a}$, hence, our pair $p_n$
and $q_n$ should satisfy the following inequality:

$$
\begin{split}
     && \sqrt[n+1]{\frac{p_n^n q_n}{n^n}} &\ge 1 \\
\iff && \sqrt[n+1]{\frac{p_n^n q_n}{n^n}} &\ge \frac{1}{n+1} \\
\iff && p_n^n q_n &\ge \frac{n^n}{(n+1)^{n+1}}
\end{split}
$$

It's easy to see that these pair would work.

$$
\begin{split}
p_n &= \frac{n}{n+1} \\
q_n &= \frac{1}{n+1} \\
\end{split}
\tag{5}
$$

## Note for later

> TODO (tai): continue or conclude 1.45
>
> I'm unable to prove or explain why $r = \lfloor log_2(n) \rfloor$ yet.
>
> I'm aware of a proof, but I'm not completely read it yet, because I want to
> prove it myself. https://deltam.blogspot.com/2015/08/sicp145ex145.html I
> learned about that link from: http://community.schemewiki.org/?sicp-ex-1.45.
>
> [Numerical Analysis](https://en.wikipedia.org/wiki/Numerical_analysis) might
> be helpful to completely solve this.

We get $p_1= q_1=\frac{1}{2}$ using above formulas. However, they are very
different with the pair come from applying average damping technique, i.e.

$$
\begin{split}
p_n &= 1-\frac{1}{2^r} \\
q_n &= \frac{1}{2^r} \\
\end{split}
\tag{6}
$$

This question is still unanswered: **how to find $r$**? There are some more
questions comming up:

- Which pair makes the series converges faster?
- What pair makes the series converge **fastest**?
- What pair stop at the **most accurate** result?

See [`./1.45.stats.md`](./1.45.stats.md) for some experiments. Below are my
observations:

- $(5)$ **often** faster than $(6)$ and **always** get more accurate result.
- There's some case the solution with a custom $q_n$ can perform faster than
  either $(5)$ or $(6)$.
- Negative guess **often** cause $(5)$ performs worse than $(6)$, however,
  there's some case $(6)$ is much slower than $(5)$.

See [`./1.45.rkt`](./1.45.rkt) for the implementation of both solutions and code
to generate the stats.
